{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f6df4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: could not create work tree dir 'ikflow': Permission denied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: File \"setup.py\" or \"setup.cfg\" not found. Directory cannot be installed in editable mode: c:\\Users\n",
      "WARNING: You are using pip version 21.1.1; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Abiy\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# %pip install git+https://github.com/jstmn/ikflow.git\n",
    "!git clone https://github.com/jstmn/ikflow.git\n",
    "# %cd ikflow\n",
    "%pip install -e .\n",
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install numpy\n",
    "# %pip install scikit-learn\n",
    "# %pip install torch\n",
    "# !poetry install --without dev\n",
    "# !poetry shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1baf528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'config', 'evaluation_utils', 'ikflow_solver', 'math_utils', 'model', 'model_loading', 'supporting_types', 'utils', 'visualizations']\n",
      "['Callable', 'DEFAULT_TORCH_DTYPE', 'DEVICE', 'Dict', 'IKFlowSolver', 'IkflowModelParameters', 'Optional', 'Robot', 'SOLUTION_EVALUATION_RESULT_TYPE', 'Tuple', 'Union', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'draw_latent', 'evaluate_solutions', 'geodesic_distance_between_quaternions', 'glow_cNF_model', 'make_text_green_or_red', 'mm_to_m', 'pickle', 'time', 'torch', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import ikflow\n",
    "print(dir(ikflow))\n",
    "import ikflow.ikflow_solver\n",
    "print(dir(ikflow.ikflow_solver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "206f79ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_ik_solver' from 'ikflow.ikflow_solver' (c:\\Users\\Abiy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ikflow\\ikflow_solver.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mikflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mikflow_solver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_ik_solver\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_ik_solver' from 'ikflow.ikflow_solver' (c:\\Users\\Abiy\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ikflow\\ikflow_solver.py)"
     ]
    }
   ],
   "source": [
    "from ikflow.ikflow_solver import get_ik_solver\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load your data\n",
    "df = pd.read_csv(\"/content/ARKOMA_LeftArmDataset/LVal_x.csv\")\n",
    "poses = torch.tensor(df.values, dtype=torch.float32).to(\"cuda\")\n",
    "\n",
    "# 2. Instantiate solver\n",
    "ik_solver, params = get_ik_solver(\n",
    "    model_name=\"panda__full__lp191_5.25m\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# 3. Generate exact solutions\n",
    "solutions, log_probs = ik_solver.generate_exact_ik_solutions(poses[:10])\n",
    "# solutions: Tensor shape (10, num_solutions, 5)\n",
    "# log_probs: likelihood scores per solution\n",
    "\n",
    "print(\"Joint solutions for first pose:\", solutions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load ARKOMA data (no Streamlit)\n",
    "def load_data():\n",
    "    base = \"/content/drive/MyDrive/ARKOMA_LeftArmDataset\"\n",
    "    df_LTrain_x = pd.read_csv(f\"{base}/LTrain_x.csv\")\n",
    "    df_LTrain_y = pd.read_csv(f\"{base}/LTrain_y.csv\")\n",
    "    df_LVal_x   = pd.read_csv(f\"{base}/LVal_x.csv\")\n",
    "    df_LVal_y   = pd.read_csv(f\"{base}/LVal_y.csv\")\n",
    "    df_LTest_x  = pd.read_csv(f\"{base}/LTest_x.csv\")\n",
    "    df_LTest_y  = pd.read_csv(f\"{base}/LTest_y.csv\")\n",
    "    return df_LTrain_x, df_LTrain_y, df_LVal_x, df_LVal_y, df_LTest_x, df_LTest_y\n",
    "\n",
    "df_LTrain_x, df_LTrain_y, df_LVal_x, df_LVal_y, df_LTest_x, df_LTest_y = load_data()\n",
    "\n",
    "print(\"Train X shape:\", df_LTrain_x.shape)\n",
    "print(\"Train Y shape:\", df_LTrain_y.shape)\n",
    "print(\"Val X shape:  \", df_LVal_x.shape)\n",
    "print(\"Val Y shape:  \", df_LVal_y.shape)\n",
    "print(\"Test X shape: \", df_LTest_x.shape)\n",
    "print(\"Test Y shape: \", df_LTest_y.shape)\n",
    "\n",
    "# 3. Extract numpy arrays\n",
    "X_train, y_train = df_LTrain_x.values, df_LTrain_y.values\n",
    "X_val,   y_val   = df_LVal_x.values,   df_LVal_y.values\n",
    "X_test,  y_test  = df_LTest_x.values,  df_LTest_y.values\n",
    "\n",
    "# 4. Scale data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled   = scaler_X.transform(X_val)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_val_scaled   = scaler_y.transform(y_val)\n",
    "y_test_scaled  = scaler_y.transform(y_test)\n",
    "\n",
    "print(\"Sample normalized input:\", X_train_scaled[0])\n",
    "print(\"Sample normalized output:\", y_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fef21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
